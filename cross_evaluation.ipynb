{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af16a57c-6e22-4399-9ff7-6d3b23d9fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.data_util import load_augmented_example, load_preprocess_examples\n",
    "from src.evaluation import DAP_SAP_MAP_kde, hist_AP, plot_SAP_MAP\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283cd7b0-d42e-4f39-b125-5025b273852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P_01_PulHyp', 'P_02_PulHyp', 'P_03_PulHyp', 'P_04_PulHyp', 'P_05_PulHyp', 'P_06_PulHyp', 'P_07_PulHyp', 'P_08_PulHyp', 'P_09_PulHyp', 'P_10_PulHyp']\n"
     ]
    }
   ],
   "source": [
    "all_pigs = [\"P_{0:02d}_PulHyp\".format(i) for i in range(1, 11)]\n",
    "print(all_pigs)\n",
    "\n",
    "pig_test_s_dict = {\n",
    "    \"P_01_PulHyp\": 10338,\n",
    "    \"P_02_PulHyp\": 12859,\n",
    "    \"P_03_PulHyp\": 8124,\n",
    "    \"P_04_PulHyp\": 8914,\n",
    "    \"P_05_PulHyp\": 10063,\n",
    "    \"P_06_PulHyp\": 6934,\n",
    "    \"P_07_PulHyp\": 5692,\n",
    "    \"P_08_PulHyp\": 7189,\n",
    "    \"P_09_PulHyp\": 8228,\n",
    "    \"P_10_PulHyp\": 6552,\n",
    "}\n",
    "\n",
    "load_path = \"/data/PulHypStudie_Check_npz_v5_SNR20/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6af2c49-2622-4a9e-8250-44bab7557326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from mapper_tuning_v5/mapper_tuning_20db/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "dap_factor = 120\n",
    "sap_factor = 180\n",
    "map_factor = 150\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    output_dim = 3\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    # input layer\n",
    "    model.add(keras.layers.Input(shape=(64, 1024, 1)))\n",
    "\n",
    "    # tune the number of hidden layers and units in each.\n",
    "    for i in range(1, hp.Int(\"num_layers\", 3, 7)):\n",
    "        print(f\"Init layer {i=}\")\n",
    "        hp_units = hp.Int(\"units_\" + str(i), min_value=2, max_value=16, step=4)\n",
    "        hp_kernel = hp.Int(\"kernel_\" + str(i), min_value=2, max_value=14, step=1)\n",
    "        # stride dim (0,1)\n",
    "        hp_strides_0 = hp.Int(\"units_0_\" + str(i), min_value=1, max_value=4, step=1)\n",
    "        hp_strides_1 = hp.Int(\"units_1_\" + str(i), min_value=2, max_value=4, step=1)\n",
    "        hp_activation = hp.Choice(\n",
    "            \"activation_\" + str(i), values=[\"relu\", \"elu\", \"tanh\"]\n",
    "        )\n",
    "        hp_dropout = hp.Float(\"dropout_\" + str(i), 0, 1.0, step=0.1)\n",
    "\n",
    "        # create layer\n",
    "        model.add(\n",
    "            keras.layers.Conv2D(\n",
    "                hp_units,\n",
    "                hp_kernel,\n",
    "                strides=(hp_strides_0, hp_strides_1),\n",
    "                padding=\"same\",\n",
    "            )\n",
    "        )\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(hp_activation))\n",
    "        model.add(keras.layers.Dropout(hp_dropout))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    # output layer.\n",
    "    model.add(keras.layers.Dense(output_dim, activation=\"linear\"))\n",
    "\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=keras.losses.MeanAbsoluteError(),\n",
    "        # loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    factor=2,\n",
    "    directory=\"mapper_tuning_v5\",\n",
    "    project_name=\"mapper_tuning_20db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ffed63-171f-4682-ba25-a3cad0a0ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOCV_nr = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f73b07-96a5-45dd-87e7-46dc8dbdec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train all pics and test on P_01_PulHyp\n",
      "['P_02_PulHyp', 'P_03_PulHyp', 'P_04_PulHyp', 'P_05_PulHyp', 'P_06_PulHyp', 'P_07_PulHyp', 'P_08_PulHyp', 'P_09_PulHyp', 'P_10_PulHyp']\n",
      "Selected 14500 from /data/PulHypStudie_Check_npz_v5_SNR20/P_02_PulHyp/sample_000500.npz to /data/PulHypStudie_Check_npz_v5_SNR20/P_02_PulHyp/sample_014999.npz from pig P_02_PulHyp.\n"
     ]
    }
   ],
   "source": [
    "for p_n, test_pig in enumerate(all_pigs):\n",
    "    print(f\"Train all pics and test on {test_pig}\")\n",
    "    curr_pigs = [\"P_{0:02d}_PulHyp\".format(i) for i in range(1, 11)]\n",
    "    del curr_pigs[p_n]\n",
    "    print(curr_pigs)\n",
    "    X_train, y_train, clrs_pig_train = load_augmented_example(\n",
    "        load_path, curr_pigs, sample_skip=500, load_samples=\"upwards\", shuffle=True\n",
    "    )\n",
    "\n",
    "    X_valid, y_valid, clrs_pig_valid = load_augmented_example(\n",
    "        load_path, curr_pigs, sample_skip=500, load_samples=\"downwards\", shuffle=True\n",
    "    )\n",
    "    X_test, Y_true, clrs_pig_test = load_augmented_example(\n",
    "        load_path,\n",
    "        [test_pig],\n",
    "        sample_skip=pig_test_s_dict[test_pig],\n",
    "        load_samples=\"downwards\",\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        X_train.shape,\n",
    "        X_valid.shape,\n",
    "        y_train.shape,\n",
    "        y_valid.shape,\n",
    "        X_test.shape,\n",
    "        Y_true.shape,\n",
    "        clrs_pig_train.shape,\n",
    "        clrs_pig_valid.shape,\n",
    "    )\n",
    "\n",
    "    y_train[:, 0] = y_train[:, 0] / dap_factor  # dap normalization\n",
    "    y_train[:, 1] = y_train[:, 1] / sap_factor  # sap normalization\n",
    "    y_train[:, 2] = y_train[:, 2] / map_factor  # map normalization\n",
    "\n",
    "    y_valid[:, 0] = y_valid[:, 0] / dap_factor  # dap normalization\n",
    "    y_valid[:, 1] = y_valid[:, 1] / sap_factor  # sap normalization\n",
    "    y_valid[:, 2] = y_valid[:, 2] / map_factor  # map normalization\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=8,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "    )\n",
    "\n",
    "    # predict EIT data of test pig\n",
    "    y_pred = model.predict(X_test)\n",
    "    Y_pred = np.empty(y_pred.shape)\n",
    "    Y_pred[:, 0] = y_pred[:, 0] * dap_factor  # dap normalization\n",
    "    Y_pred[:, 1] = y_pred[:, 1] * sap_factor  # sap normalization\n",
    "    Y_pred[:, 2] = y_pred[:, 2] * map_factor  # map normalization\n",
    "\n",
    "    np.savez(\n",
    "        f\"LOOCV{LOOCV_nr}/test_{test_pig}.npz\",\n",
    "        history=history.history,\n",
    "        Y_pred=Y_pred,\n",
    "        Y_true=Y_true,\n",
    "    )\n",
    "\n",
    "    model.save_weights(f\"LOOCV{LOOCV_nr}/model_{test_pig}.weights.h5\")\n",
    "\n",
    "    DAP_err = Y_pred[:, 0] - Y_true[:, 0]\n",
    "    SAP_err = Y_pred[:, 1] - Y_true[:, 1]\n",
    "    MAP_err = Y_pred[:, 2] - Y_true[:, 2]\n",
    "    DF_err = pd.DataFrame({\"DAP\": DAP_err, \"SAP\": SAP_err, \"MAP\": MAP_err})\n",
    "    DF_err.to_csv(f\"LOOCV{LOOCV_nr}/err_{test_pig}.csv\", index=False)\n",
    "    sns.histplot(DF_err)\n",
    "    plt.savefig(f\"LOOCV{LOOCV_nr}/histplot_{test_pig}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.boxplot(DF_err)\n",
    "    plt.grid()\n",
    "    plt.ylim([-50, 50])\n",
    "    plt.savefig(f\"LOOCV{LOOCV_nr}/boxplot_{test_pig}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(Y_pred[:, 0], label=\"Pred\")\n",
    "    plt.plot(Y_true[:, 0], label=\"True\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"LOOCV{LOOCV_nr}/boxplot_{test_pig}.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
